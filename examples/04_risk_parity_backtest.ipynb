{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9588e3f4",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "The first step in any Python script or Jupyter notebook is to import the necessary libraries. Here, we are importing the libraries we need to optimize our portfolios and run the backtest with Zipline Reloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cc424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import riskfolio as rp\n",
    "\n",
    "from zipline import run_algorithm\n",
    "from zipline.pipeline import Pipeline\n",
    "from zipline.pipeline.factors import AverageDollarVolume, VWAP, AnnualizedVolatility, SimpleBeta\n",
    "from zipline.api import (\n",
    "    symbol,\n",
    "    attach_pipeline,\n",
    "    calendars,\n",
    "    pipeline_output,\n",
    "    date_rules,\n",
    "    time_rules,\n",
    "    get_datetime,\n",
    "    record,\n",
    "    order_target_percent,\n",
    "    get_open_orders,\n",
    "    schedule_function,\n",
    "    set_commission,\n",
    "    set_slippage,\n",
    "    set_benchmark\n",
    ")\n",
    "from zipline.finance import commission, slippage\n",
    "from zipline.data import bundles\n",
    "from zipline.utils.run_algo import load_extensions\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e44bad8",
   "metadata": {},
   "source": [
    "### Option 1: Use the built in bundle with free data\n",
    "This option uses the built in data bundle provided by Zipline. It then acquires free US equities data that extend through 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41440613-260f-4c51-a9d0-fd581373d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"QUANDL_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "bundle = \"quandl\"\n",
    "bundles.ingest(bundle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05a6ed6",
   "metadata": {},
   "source": [
    "### Option 2: Use the custom bundle with premium data\n",
    "This option uses the custom bundle with premium data. You can find the detailed instructions to set this up here: https://www.pyquantnews.com/free-python-resources/how-to-ingest-premium-market-data-with-zipline-reloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f584706",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DATALINK_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "bundle = \"quotemedia\"\n",
    "load_extensions(True, [], False, os.environ)\n",
    "bundles.ingest(bundle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a81a06",
   "metadata": {},
   "source": [
    "### Trade settings\n",
    "Instead of hard coding these settings inside the backtest, we'll make it easier on ourselves by setting them up front.\n",
    "\n",
    "This code defines `leverage` as 1.5, indicating that the trading strategy can borrow up to 50% more capital than the amount initially invested. `window_length` and `bar_count` are both set to 126 (21 days multiplied by 6, representing six trading months), defining the number of trading bars (e.g., days) to consider for calculations. `top_n` is set to 100, specifying that the strategy will focus on the top 100 assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c0899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "leverage = 1.5\n",
    "window_length = 21 * 6\n",
    "bar_count = window_length\n",
    "top_n = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb30054-cd41-4c06-8971-1d01764c702e",
   "metadata": {},
   "source": [
    "### Create the Pipeline\n",
    "A Pipeline is a framework that allows for the definition and efficient computation of a wide array of financial data over a set of assets.\n",
    "\n",
    "Inside the Pipeline, we use factors like `AverageDollarVolume`, `VWAP` (volume-weighted average price), `AnnualizedVolatility`, and `SimpleBeta` are calculated, each using the window_length to define the lookback period. The `SimpleBeta` factor specifically calculates the beta of stocks relative to the S&P 500 (SPY). A screening condition is set up to filter stocks where the `VWAP` is above $50, annualized volatility is between 35-60%, and beta is between 0.5 and 1.0. The pipeline returns a dictionary of columns where longs are stocks in the top top_n by dollar volume, filtered by the defined conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec58038-dc65-429e-a404-8c20b2f4f4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline():\n",
    "    \n",
    "    dollar_volume = AverageDollarVolume(window_length=window_length)\n",
    "    vwap = VWAP(window_length=window_length)\n",
    "    annualized_volatility = AnnualizedVolatility(window_length=window_length)\n",
    "    beta = SimpleBeta(target=symbol(\"SPY\"), regression_length=window_length)\n",
    "\n",
    "    screen = (\n",
    "        (vwap > 50.0) & \n",
    "        (0.35 < annualized_volatility <= 0.60) & \n",
    "        (0.5 < beta < 1.0)\n",
    "    )\n",
    "    \n",
    "    return Pipeline(\n",
    "        columns={\n",
    "            \"longs\": dollar_volume.top(top_n),\n",
    "        },\n",
    "        screen=screen\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e61cd9-9846-41d8-adae-94bbbb94a93e",
   "metadata": {},
   "source": [
    "### Recalculate the pipeline\n",
    "\n",
    "The function `before_trading_start` executes before the rabalance period. It retrieves the output of a previously defined pipeline named \"screener\" and stores it in the context object under the attribute screener. This lets use use it throughout other parts of the trading algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ebda90-ed40-49ab-8233-89d0ee607460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def before_trading_start(context, data):\n",
    "    context.screener = pipeline_output(\"screener\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062cff4e-2d01-4b41-ae66-298dc0e4ca3a",
   "metadata": {},
   "source": [
    "### Initialize the backtest\n",
    "\n",
    "The initialize function sets up the initial configuration for our backtest.\n",
    "\n",
    "It attaches a defined pipeline named \"screener\" to the trading context and schedules a function rebalance to run at the start of each week when the market opens, specifically for the US equities calendar. Commission and slippage models are defined to manage transaction costs and market impact, respectively, with specific parameters for per-share costs and volume limits. Additionally, the S&P 500 ETF (SPY) is set as the benchmark for performance comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f079480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(context):\n",
    "    attach_pipeline(make_pipeline(), \"screener\")\n",
    "    \n",
    "    schedule_function(\n",
    "        rebalance,\n",
    "        date_rules.week_start(),\n",
    "        time_rules.market_open(),\n",
    "        calendar=calendars.US_EQUITIES,\n",
    "    )\n",
    "\n",
    "    # Set up the commission model to charge us per share and a volume slippage model\n",
    "    set_commission(\n",
    "        us_equities=commission.PerShare(\n",
    "            cost=0.005,\n",
    "            min_trade_cost=2.0\n",
    "        )\n",
    "    )\n",
    "    set_slippage(\n",
    "        us_equities=slippage.VolumeShareSlippage(\n",
    "            volume_limit=0.0025, \n",
    "            price_impact=0.01\n",
    "        )\n",
    "    )\n",
    "    # SPY is only available in the premium data bundle. You can use any symbol you\n",
    "    # want for the benchmark.\n",
    "    set_benchmark(symbol(\"SPY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cd9194-eaf7-4bbd-8641-313802890d8f",
   "metadata": {},
   "source": [
    "### Create a function to compute the weights\n",
    "\n",
    "The `compute_weights` function calculates optimal portfolio weights based on historical price data of assets.\n",
    "\n",
    "The function initializes a Riskfolio `portfolio` object with the asset returns and specifies the methods for calculating mean returns and covariance, using historical data. Note the covariance matrix is calculated using the Ledoit-Wolf covariance shrinkage method. It sets a minimum expected return for the optimization based on a specified value. Finally, the function optimizes the portfolio using a mean-variance model, considering historical data, and returns the optimized weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8bf885-06f9-45d0-8727-d22fa349c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(returns):\n",
    "\n",
    "    port = rp.Portfolio(returns=returns)\n",
    "    port.assets_stats(method_mu=\"hist\", method_cov=\"ledoit\")\n",
    "    port.lowerret = 0.00085\n",
    "    \n",
    "    return port.rp_optimization(\n",
    "        model=\"Classic\", \n",
    "        rm=\"MV\", \n",
    "        b=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f6efca",
   "metadata": {},
   "source": [
    "### Set our rebalance logic\n",
    "In the rebalance function, we extract the asset universe from our pipeline's DataFrame and identify which stocks to go long on and which to divest. We calculate historical prices for the target assets, and if the returns are valid, we compute optimal weights using a volatility targeting algorithm, adjusting for leverage. On rebalance days, we log our actions, showing the number of assets longed, divested, and the portfolio's value. Finally, we execute trades to realign our portfolio according to these calculated weights, ensuring it meets our strategic objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b80da01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebalance(context, data):\n",
    "\n",
    "    # Get the output of the Pipeline which is a pandas DataFrame.\n",
    "    screened = context.screener\n",
    "\n",
    "    # Get the list the universe of assets to consider in portfolio\n",
    "    # construction\n",
    "    assets = screened.index\n",
    "\n",
    "    # Get the symbols of those stocks we want to go long\n",
    "    longs = assets[screened.longs]\n",
    "\n",
    "    # Figure out which assets are no longer required in our portfolio\n",
    "    # based on universe construction. Build a DataFrame suitable for\n",
    "    # passing into exec_trades\n",
    "    divest = list(set(context.portfolio.positions.keys()) - set(longs))\n",
    "    divest_weights = pd.DataFrame(\n",
    "        np.zeros(len(divest)), \n",
    "        index=divest, \n",
    "        columns=[\"weights\"]\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"{get_datetime().date()} \"\n",
    "        f\"Longs={len(longs)} \"\n",
    "        f\"Divest={len(divest)} \"\n",
    "        f\"Value:={context.portfolio.portfolio_value} \"\n",
    "    )\n",
    "\n",
    "    # Get the historic prices for the assets we want to buy.\n",
    "    prices = data.history(\n",
    "        longs, \n",
    "        \"price\", \n",
    "        bar_count=bar_count, \n",
    "        frequency=\"1d\"\n",
    "    )\n",
    "\n",
    "    # Divest the assets we no longer want\n",
    "    exec_trades(data, assets=divest, weights=divest_weights)\n",
    "\n",
    "    # Compute the returns of the assets we want to buy, drop any symbols\n",
    "    # where there are NaNs (no data), and select assets where we have daily\n",
    "    # returns that change ie avoid stocks where the price is the the same\n",
    "    # every day\n",
    "    returns = prices.pct_change()[1:]\n",
    "    returns.dropna(how=\"any\", axis=1, inplace=True)\n",
    "    returns = returns.loc[:, (returns != 0).any(axis=0)]\n",
    "\n",
    "    # Make sure we have asset returns to optimize against\n",
    "    if returns.empty:\n",
    "        return\n",
    "\n",
    "    # Get the weights based on our constrained volatility targeting algorithm.\n",
    "    weights = compute_weights(returns)\n",
    "\n",
    "    # If we have weights, execute the trades.\n",
    "    if weights is not None:\n",
    "\n",
    "        weights *= leverage\n",
    "        \n",
    "        exec_trades(data, assets=longs, weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8989db1b",
   "metadata": {},
   "source": [
    "### Execute the trades\n",
    "We loop through every asset, determine if it's tradeable, the asset is weighted, and there are no open orders. Then we order the target percent and Zipline rebalances our portfolio for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5270a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_trades(data, assets, weights):\n",
    "    # Loop through every asset...\n",
    "    for asset in assets:\n",
    "        # ...if the asset is tradeable and there are no open orders...\n",
    "        if data.can_trade(asset) and asset in weights.index and not get_open_orders(asset):\n",
    "            # ...execute the order against the target percent\n",
    "            target_percent = weights.at[asset, \"weights\"]\n",
    "            order_target_percent(asset, target_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642676f6",
   "metadata": {},
   "source": [
    "### Analyze the results\n",
    "We can ask Zipline to run a function at the conclusion of the backtest. In this case, we simply print the equity curve and cache the backtest output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2eafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(context, perf):\n",
    "    # You can execute any arbitrary code here. This includes saving results\n",
    "    # to a database, sending yourself an email, send a note to Discord, or\n",
    "    # even executing trades.\n",
    "    perf.portfolio_value.plot()\n",
    "    perf.to_pickle(\"constrained.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db3e409",
   "metadata": {},
   "source": [
    "### Run the backtest\n",
    "The `run_algorithm` funtion kicks off the backtest. It takes the `start` and `end` date, the `initialize` function that runs at the inception of the backtest, the `analyze` function that runs at the conclusion of the backtest, the `capital` to start the backtest with, and the name of the bundle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec09bc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perf = run_algorithm(\n",
    "    start=pd.Timestamp(\"2015-01-01\"),\n",
    "    end=pd.Timestamp(\"2023-12-31\"),\n",
    "    initialize=initialize,\n",
    "    before_trading_start=before_trading_start,\n",
    "    analyze=analyze,\n",
    "    capital_base=100_000,\n",
    "    bundle=\"quotemedia\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d87306-cccf-4c4d-a471-cb38028e9c4f",
   "metadata": {},
   "source": [
    "### Cache the results for later analysis\n",
    "Since `perf` is a pandas DataFrame, we can use the `to_pickle` method to save a serialized copy of the pandas DataFrame to disk. We'll need this later when we assess this strategy's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1424d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf.to_pickle(\"risk-parity.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedd51fb-86f5-45b2-b226-84d54381368b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
